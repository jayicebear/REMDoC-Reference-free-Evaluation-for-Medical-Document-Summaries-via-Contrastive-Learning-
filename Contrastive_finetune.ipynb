{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50a45c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train :  10501\n",
      "Length of Valid :  1167\n",
      "Length of Test :  519\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load KLUE-STS Dataset\n",
    "klue_sts_train = load_dataset(\"klue\", \"sts\", split='train[:90%]')\n",
    "klue_sts_valid = load_dataset(\"klue\", \"sts\", split='train[-10%:]') # train의 10%를 validation set으로 사용\n",
    "klue_sts_test = load_dataset(\"klue\", \"sts\", split='validation')\n",
    "\n",
    "print('Length of Train : ',len(klue_sts_train)) # 10501\n",
    "print('Length of Valid : ',len(klue_sts_valid)) # 1167\n",
    "print('Length of Test : ',len(klue_sts_test)) # 519          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64db16be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://velog.io/@jaehyeong/Basic-NLP-sentence-transformers-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-SBERT-%ED%95%99%EC%8A%B5-%EB%B0%A9%EB%B2%95\n",
    "import json\n",
    "with open('Test_data/Syn.json','r') as f :\n",
    "    one=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "488859ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('Test_data/RD.json','r') as f :\n",
    "    two=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65b45def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('Test_data/RS.json','r') as f :\n",
    "    three=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70b0d62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('Test_data/RI.json','r') as f :\n",
    "    four=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "633fd2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('Test_data/AR.json','r') as f :\n",
    "    five=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67579f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('Test_data/NS.json','r') as f :\n",
    "    six=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "31078025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ner swqp data\n",
    "import json\n",
    "with open('Test_data/P.json','r') as f :\n",
    "    seven=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c451b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = one + two + three +four +five + six + seven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe0b19c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22512"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb2d7f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('Test_data/one_ner_list.json','r') as f :\n",
    "    one=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9af339d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('Test_data/three_ner_list.json','r') as f :\n",
    "    three=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cd38ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('Test_data/five_ner_list.json','r') as f :\n",
    "    five=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0e769d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('Test_data/seven_ner_list.json','r') as f :\n",
    "    seven=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffc4d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9215a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1~ 6 은 모두 3752 개 이고 7(P) 은 1255 개가 있다  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "764ec95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1개 \n",
    "klue_sts_train = trainset[:3002]\n",
    "klue_sts_valid = trainset[3002:3377]\n",
    "klue_sts_test = trainset[3377:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550380d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2개 \n",
    "klue_sts_train = trainset[:6003]\n",
    "klue_sts_valid = trainset[6003:6753]\n",
    "klue_sts_test = trainset[6753:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d585e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3개 \n",
    "klue_sts_train = trainset[:9005]\n",
    "klue_sts_valid = trainset[9005:10131]\n",
    "klue_sts_test = trainset[10131:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c42e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4개\n",
    "klue_sts_train = trainset[:12006]\n",
    "klue_sts_valid = trainset[12006:13507]\n",
    "klue_sts_test = trainset[13507:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cbc26a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5개\n",
    "klue_sts_train = trainset[:15008]\n",
    "klue_sts_valid = trainset[15008:16884]\n",
    "klue_sts_test = trainset[16884:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "080277b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6개\n",
    "klue_sts_train = trainset[:18010]\n",
    "klue_sts_valid = trainset[18010:20261]\n",
    "klue_sts_test = trainset[20261:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d9c0cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1~7 까지 모든 데이터 8:1:1 로 나눈거\n",
    "klue_sts_train = trainset[:19014]\n",
    "klue_sts_valid = trainset[19014:21391]\n",
    "klue_sts_test = trainset[21391:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0e6204b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In the surgical treatment of tubal ectopic pregnancy laparoscopic surgery is a cost effective treatment. An alternative non surgical treatment option in selected patients is medical treatment with systemic methotrexate. Expectant management can not be adequately evaluated yet.',\n",
       " ['Laparoscopic surgery is an effective treatment for tubal ectopic pregnancies.'],\n",
       " 0.8192948698997498]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_sts_train[12020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6591dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.readers import InputExample\n",
    "\n",
    "def make_sts_input(dataset):\n",
    "    try:\n",
    "        input_= []\n",
    "        for i, data in enumerate(dataset):\n",
    "            sentence1 = data[0]\n",
    "            sentence2 = data[1]\n",
    "            score = data[2]\n",
    "            input_.append(InputExample(texts=[sentence1, sentence2], label=score))\n",
    "    except:\n",
    "        print(i)\n",
    "    return input_\n",
    "    \n",
    "sts_train = make_sts_input(klue_sts_train)\n",
    "sts_valid= make_sts_input(klue_sts_valid)\n",
    "sts_test = make_sts_input(klue_sts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcde35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "# Train Dataloader\n",
    "train_dataloader = DataLoader(\n",
    "    sts_train,\n",
    "    shuffle=True,\n",
    "    batch_size=32, \n",
    ")\n",
    "\n",
    "# Evaluator by sts-validation\n",
    "dev_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "    sts_valid,\n",
    "    name=\"sts-dev\",\n",
    ")\n",
    "\n",
    "# Evaluator by sts-test\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "    sts_test,\n",
    "    name=\"sts-test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9d4b237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/jayicebear/.local/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/sw/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-11.4.0/cuda-11.8.0-pfc6itin63yafh5iqlnuuzfopjbo2irw/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.9\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /home/jayicebear/.local/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayicebear/.local/lib/python3.11/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib')}\n",
      "  warn(msg)\n",
      "2024-05-27 20:06:27.781501: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-27 20:06:27.781547: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-27 20:06:27.782791: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-27 20:06:27.788988: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-27 20:06:28.929787: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load Embedding Model\n",
    "embedding_model = models.Transformer(\n",
    "  #  model_name_or_path = 'pritamdeka/S-PubMedBert-MS-MARCO-SCIFACT',\n",
    "    #model_name_or_path=\"lighteternal/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext-finetuned-mnli\", \n",
    "    #model_name_or_path = \"FacebookAI/xlm-roberta-base\",\n",
    "    #model_name_or_path = 'microsoft/deberta-v3-base',\n",
    "    #model_name_or_path = 'google-bert/bert-base-uncased',\n",
    "    #model_name_or_path = 'FacebookAI/roberta-large',\n",
    "    #model_name_or_path = 'klue/roberta-small',\n",
    "    #model_name_or_path = 'google/electra-base-discriminator',\n",
    "    #model_name_or_path = 'sentence-transformers/all-mpnet-base-v2',\n",
    "    #model_name_or_path = 'distilbert/distilroberta-base',\n",
    "    max_seq_length=256,\n",
    "    do_lower_case=True\n",
    ")\n",
    "\n",
    "# Only use Mean Pooling -> Pooling all token embedding vectors of sentence.\n",
    "pooling_model = models.Pooling(\n",
    "    embedding_model.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens=True,\n",
    "    pooling_mode_cls_token=False,\n",
    "    pooling_mode_max_tokens=False,\n",
    ")\n",
    "\n",
    "model = SentenceTransformer(modules=[embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac928b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd59a25b5d846dd86df91610f213859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ad6d71f42d4fd1bf83c3d60e7d3451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:5445: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:5445: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:5445: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:5445: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:5445: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:5445: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:5445: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:5445: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:5445: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:5445: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:5445: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9106f115e73c476da79467b1dbac85ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/home/sw/miniconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:5445: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m warmup_steps \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mceil(\u001b[38;5;28mlen\u001b[39m(sts_train) \u001b[38;5;241m*\u001b[39m sts_num_epochs \u001b[38;5;241m/\u001b[39m train_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m) \u001b[38;5;66;03m#10% of train data for warm-up\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Traininsesssg\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     14\u001b[0m     train_objectives\u001b[38;5;241m=\u001b[39m[(train_dataloader, train_loss)],\n\u001b[1;32m     15\u001b[0m     evaluator\u001b[38;5;241m=\u001b[39mdev_evaluator,\n\u001b[1;32m     16\u001b[0m     epochs\u001b[38;5;241m=\u001b[39msts_num_epochs,\n\u001b[1;32m     17\u001b[0m     evaluation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_dataloader)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.1\u001b[39m),\n\u001b[1;32m     18\u001b[0m     warmup_steps\u001b[38;5;241m=\u001b[39mwarmup_steps,\n\u001b[1;32m     19\u001b[0m     output_path\u001b[38;5;241m=\u001b[39msts_model_save_path  \n\u001b[1;32m     20\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:735\u001b[0m, in \u001b[0;36mSentenceTransformer.fit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    732\u001b[0m global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluation_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m training_steps \u001b[38;5;241m%\u001b[39m evaluation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_during_training(evaluator, output_path, save_best_model, epoch, training_steps, callback)\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m loss_model \u001b[38;5;129;01min\u001b[39;00m loss_models:\n\u001b[1;32m    738\u001b[0m         loss_model\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:777\u001b[0m, in \u001b[0;36mSentenceTransformer._eval_during_training\u001b[0;34m(self, evaluator, output_path, save_best_model, epoch, steps, callback)\u001b[0m\n\u001b[1;32m    774\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(eval_path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 777\u001b[0m     score \u001b[38;5;241m=\u001b[39m evaluator(\u001b[38;5;28mself\u001b[39m, output_path\u001b[38;5;241m=\u001b[39meval_path, epoch\u001b[38;5;241m=\u001b[39mepoch, steps\u001b[38;5;241m=\u001b[39msteps)\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    779\u001b[0m         callback(score, epoch, steps)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sentence_transformers/evaluation/EmbeddingSimilarityEvaluator.py:78\u001b[0m, in \u001b[0;36mEmbeddingSimilarityEvaluator.__call__\u001b[0;34m(self, model, output_path, epoch, steps)\u001b[0m\n\u001b[1;32m     75\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbeddingSimilarityEvaluator: Evaluating the model on \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m out_txt)\n\u001b[1;32m     77\u001b[0m embeddings1 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentences1, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_progress_bar, convert_to_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 78\u001b[0m embeddings2 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentences2, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_progress_bar, convert_to_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     79\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscores\n\u001b[1;32m     81\u001b[0m cosine_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (paired_cosine_distances(embeddings1, embeddings2))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:188\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;66;03m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[39;00m\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m convert_to_numpy:\n\u001b[0;32m--> 188\u001b[0m                 embeddings \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    190\u001b[0m         all_embeddings\u001b[38;5;241m.\u001b[39mextend(embeddings)\n\u001b[1;32m    192\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m [all_embeddings[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39margsort(length_sorted_idx)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sentence_transformers import losses\n",
    "import math\n",
    "# config\n",
    "sts_num_epochs = 4\n",
    "train_batch_size = 24\n",
    "sts_model_save_path = 'logs/ss33332w32w3sx/training_sts-'\n",
    "\n",
    "# Use CosineSimilarityLoss\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "# linear learning-rate warmup steps\n",
    "warmup_steps = math.ceil(len(sts_train) * sts_num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "# Traininsesssg\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=dev_evaluator,\n",
    "    epochs=sts_num_epochs,\n",
    "    evaluation_steps=int(len(train_dataloader)*0.1),\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=sts_model_save_path  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57904b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b9ed5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(model,'Test_models/one_ner_list.pth')\n",
    "#model.save('/home/jayicebear/snap/Medi_contrastive/asdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MDsum",
   "language": "python",
   "name": "mdsum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
